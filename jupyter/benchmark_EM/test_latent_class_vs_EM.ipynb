{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook I try to showcase the fact that `LatentClassAnalysis.jl` EM algo is a particular case of the `ExpectationMaximization.jl` when you consider the data as coming from a Mixture of Product of Categorical variables.\n",
    "I show how to go from `MixtureModels` notation to `LCA` notation and vice verca.\n",
    "I compare the result of EM algo from `LCA.jl` and `EM.jl` $\\Rightarrow$ they are exacly the same. I also compare the results of the `predict` function.\n",
    "I do some timing benchmarking between the two packages."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "StableRNGs.LehmerRNG(state=0x00000000000000000000000000000003)"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "using Test\n",
    "using LatentClassAnalysis\n",
    "using Distributions\n",
    "using BenchmarkTools\n",
    "\n",
    "using StableRNGs\n",
    "using Random\n",
    "Random.seed!(StableRNG(123), 1)"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# From you runtest.jl"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define data"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000-element Vector{Int64}:\n 2\n 1\n 1\n 1\n 1\n 1\n 2\n 2\n 1\n 2\n ⋮\n 2\n 1\n 2\n 1\n 2\n 1\n 1\n 2\n 2"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "n_samples = 10000  # Increased sample size\n",
    "n_items = 2     # Reduced number of items for simpler model\n",
    "n_categories = 2\n",
    "\n",
    "n_classes = 2\n",
    "true_classes = rand(1:n_classes, n_samples)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate data\n",
    "! Works only for two class of two categories => not very convenient"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000×2 Matrix{Int64}:\n 1  1\n 1  2\n 1  2\n 2  1\n 1  1\n 1  1\n 1  2\n 1  2\n 1  1\n 2  1\n ⋮  \n 1  2\n 1  1\n 1  1\n 1  1\n 1  1\n 2  1\n 1  1\n 2  2\n 1  2"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "data = zeros(Int, n_samples, n_items)\n",
    "for i in 1:n_samples\n",
    "    for j in 1:n_items\n",
    "        data[i, j] = true_classes[i] == 1 ? rand() < 0.8 ? 1 : 2 : rand() < 0.3 ? 1 : 2\n",
    "    end\n",
    "end\n",
    "data"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "<=> this should be\n",
    "ℙ(class = 1) = ℙ(class = 2) = 1/2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ℙ(Xⱼ = 1 ∣ class = 1) = 1 - ℙ(Xⱼ = 2 ∣ class = 1) = 0.8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ℙ(Xⱼ = 1 ∣ class = 2) = 1 - ℙ(Xⱼ = 2 ∣ class = 2) = 0.3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<=> this should be equivalent to the following `MixtureModels`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MixtureModel{Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}}(K = 2)\ncomponents[1] (prior = 0.5000): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.8, 0.2]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.8, 0.2])])\ncomponents[2] (prior = 0.5000): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.3, 0.7]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.3, 0.7])])\n"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "prob_jck = fill([0.8 0.3;\n",
    "                 0.2 0.7], n_items)\n",
    "\n",
    "prob_class = ones(n_classes)/n_classes\n",
    "dist_true = MixtureModel([product_distribution([Categorical(prob_jck[j][:,k]) for j in 1:n_items]) for k in 1:n_classes], prob_class)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that `Distributions.jl` and most Julia conventions uses number of features in rows and number of samples in columns. This is faster for some operations when you have to iterate over lines due to [Julia column major](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-column-major).\n",
    "However, Tables convention (DataFrames and so on) is opposite. So your choice makes sense with respect to that. However internal package computations could potentially be speed up with the first convention."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is very easy to generate from distributions (note the `permutedims` to accomodate your Table-like convention)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000×2 Matrix{Int64}:\n 1  1\n 1  2\n 2  1\n 1  1\n 2  1\n 2  2\n 2  1\n 2  1\n 2  2\n 1  2\n ⋮  \n 2  1\n 2  2\n 2  2\n 1  1\n 1  1\n 1  1\n 2  2\n 1  1\n 1  2"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "data_with_mix = rand(dist_true, n_samples) |> permutedims"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define LCA model"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LatentClassAnalysis.LCAModel(2, 2, [2, 2], [0.5, 0.5], [[0.6785448340529776 0.32145516594702234; 0.3038953667817837 0.6961046332182164], [0.3126376367475817 0.6873623632524183; 0.31456578882838515 0.6854342111716148]])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "model = LCAModel(n_classes, n_items, fill(n_categories, n_items))\n",
    "model_0 = deepcopy(model) # initial unfitted model"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using `ExpectationMaximization.jl`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ExpectationMaximization"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "This shows how to go from LCA structure to a MixtureModel."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MixtureModel{Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}}(K = 2)\ncomponents[1] (prior = 0.5000): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.6785448340529776, 0.32145516594702234]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.3126376367475817, 0.6873623632524183])])\ncomponents[2] (prior = 0.5000): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.3038953667817837, 0.6961046332182164]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.31456578882838515, 0.6854342111716148])])\n"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "dist_ini = MixtureModel([product_distribution([Categorical(item_prob[k, :]) for item_prob in model.item_probs]) for k in eachindex(model.class_probs)], model.class_probs)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "And back just to check that we have the same initial point"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "class_probs = probs(dist_ini)\n",
    "item_probs = [permutedims(hcat([probs(d.v[j]) for (k, d) in enumerate(components(dist_ini))]...)) for j in 1:n_items]\n",
    "@test class_probs == model.class_probs\n",
    "@test item_probs == model.item_probs"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-13461.366356633294"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "dist_fit = fit_mle(dist_ini, permutedims(data), atol=1e-3, maxiter=1000) # from ExpectationMaximization.jl\n",
    "class_probs = probs(dist_fit)\n",
    "item_probs = [permutedims(hcat([probs(d.v[j]) for (k, d) in enumerate(components(dist_fit))]...)) for j in 1:n_items]\n",
    "ll_high_tol = fit!(model, data, tol=1e-3, max_iter=1000)\n",
    "ll_EM = loglikelihood(dist_fit, permutedims(data))"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test results are the same"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "@test ll_high_tol ≈ ll_EM"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "@test class_probs ≈ model.class_probs"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "@test item_probs ≈ model.item_probs"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some timing and memory allocation"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  27.792 ms (1021837 allocations: 67.67 MiB)\n",
      "  12.387 ms (537 allocations: 5.90 MiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MixtureModel{Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}}(K = 2)\ncomponents[1] (prior = 0.5214): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.802770855546048, 0.19722914445395207]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.7699411084544469, 0.23005889154555326])])\ncomponents[2] (prior = 0.4786): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.2606458220201462, 0.7393541779798538]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.32440612601227664, 0.6755938739877233])])\n"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "@btime fit!(model_, $data, tol=1e-3, max_iter=1000) setup = (model_ = deepcopy(model_0))\n",
    "@btime ExpectationMaximization.fit_mle($dist_ini, $(permutedims(data)), atol=1e-3, maxiter=1000)"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000-element Vector{Int64}:\n 1\n 1\n 1\n 2\n 1\n 1\n 1\n 1\n 1\n 2\n ⋮\n 1\n 1\n 1\n 1\n 1\n 2\n 1\n 2\n 1"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "LCA_p_class, LCA_p_proba = LatentClassAnalysis.predict(model, data)\n",
    "EM_p_proba = ExpectationMaximization.predict_proba(dist_fit, permutedims(data))\n",
    "EM_p_class = ExpectationMaximization.predict(dist_fit, permutedims(data))"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test results are the same"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "cell_type": "code",
   "source": [
    "@test EM_p_proba ≈ LCA_p_proba"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "cell_type": "code",
   "source": [
    "@test EM_p_class == LCA_p_class"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# More complexe cases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define data"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "cell_type": "code",
   "source": [
    "n_samples = 10000  # Increased sample size\n",
    "n_categoriesⱼ = [4, 2, 3, 5] # number of possible values for each element depending on the col\n",
    "n_items = length(n_categoriesⱼ)  # number of cols\n",
    "n_classes = 3 # latent class / hidden state"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Dirichlet` distribution generate random proba vector i.e. sum = 1"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000×4 Matrix{Int64}:\n 2  1  2  1\n 2  2  3  4\n 2  1  3  1\n 1  2  3  5\n 3  2  2  5\n 4  1  2  5\n 4  1  2  4\n 2  1  3  4\n 2  2  2  5\n 3  2  3  4\n ⋮        \n 1  2  2  5\n 4  1  2  1\n 2  2  2  5\n 1  2  2  1\n 1  2  2  5\n 2  1  3  3\n 4  2  3  4\n 2  1  3  5\n 2  1  3  4"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "cell_type": "code",
   "source": [
    "prob_jck = [rand(Dirichlet(ones(n_categoriesⱼ[j])), n_classes) for j in 1:n_items]\n",
    "\n",
    "prob_class = rand(Dirichlet(ones(n_classes)))\n",
    "\n",
    "dist_true = MixtureModel([product_distribution([Categorical(prob_jck[j][:,k]) for j in 1:n_items]) for k in 1:n_classes], prob_class)\n",
    "data_with_mix = rand(dist_true, n_samples) |> permutedims"
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then same as before\n",
    "## Define LCA model"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LatentClassAnalysis.LCAModel(3, 4, [4, 2, 3, 5], [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [[0.39261086508278253 0.017104271299546062 0.34985564501995126 0.24042921859772012; 0.28301048737348794 0.007001021437446395 0.35751793344519156 0.3524705577438742; 0.20552861413914586 0.10329268755678474 0.3407428714195767 0.35043582688449265], [0.9856192419644934 0.014380758035506692; 0.27665949243708315 0.7233405075629169; 0.7775647116100953 0.22243528838990467], [0.11945928342037833 0.10523315700403439 0.7753075595755874; 0.2125652783044106 0.5986079024848703 0.1888268192107193; 0.23346794601571397 0.23733740655060195 0.529194647433684], [0.045315941538938996 0.26017542276910277 … 0.11027783161229404 0.1467263657937106; 0.28264534687937504 0.19765269545622646 … 0.10497537733835526 0.16465829831487755; 0.15281292949359235 0.2877816126297132 … 0.23007681905855848 0.024913511727406107]])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "cell_type": "code",
   "source": [
    "model = LCAModel(n_classes, n_items, n_categoriesⱼ)\n",
    "model_0 = deepcopy(model) # initial unfitted model"
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using `ExpectationMaximization.jl`"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "cell_type": "code",
   "source": [
    "dist_ini = MixtureModel([product_distribution([Categorical(item_prob[k, :]) for item_prob in model.item_probs]) for k in eachindex(model.class_probs)], model.class_probs)\n",
    "class_probs = probs(dist_ini)\n",
    "item_probs = [permutedims(hcat([probs(d.v[j]) for (k, d) in enumerate(components(dist_ini))]...)) for j in 1:n_items]\n",
    "@test class_probs == model.class_probs\n",
    "@test item_probs == model.item_probs"
   ],
   "metadata": {},
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fit"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-43063.79475073083"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "cell_type": "code",
   "source": [
    "dist_fit = fit_mle(dist_ini, permutedims(data_with_mix), atol=1e-3, maxiter=1000) # from ExpectationMaximization.jl\n",
    "class_probs = probs(dist_fit)\n",
    "item_probs = [permutedims(hcat([probs(d.v[j]) for (k, d) in enumerate(components(dist_fit))]...)) for j in 1:n_items]\n",
    "ll_high_tol = fit!(model, data_with_mix, tol=1e-3, max_iter=1000)\n",
    "ll_EM = loglikelihood(dist_fit, permutedims(data_with_mix))"
   ],
   "metadata": {},
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test results are the same"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "cell_type": "code",
   "source": [
    "@test ll_high_tol ≈ ll_EM"
   ],
   "metadata": {},
   "execution_count": 23
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "cell_type": "code",
   "source": [
    "@test class_probs ≈ model.class_probs"
   ],
   "metadata": {},
   "execution_count": 24
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "cell_type": "code",
   "source": [
    "@test item_probs ≈ model.item_probs"
   ],
   "metadata": {},
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some timing and memory allocation"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.809 s (60516001 allocations: 9.68 GiB)\n",
      "  1.459 s (47538 allocations: 384.54 MiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MixtureModel{Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}}(K = 3)\ncomponents[1] (prior = 0.0972): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(4), p=[0.08663734734699823, 0.11601870687791252, 0.040942726057726, 0.7564012197173632]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.6063050834364218, 0.39369491656357825]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.1883827512639968, 0.1560908302206163, 0.655526418515387]), Distributions.Categorical{Float64, Vector{Float64}}(\nsupport: Base.OneTo(5)\np: [0.4160705731970876, 0.12250259737314552, 0.09849368742056837, 0.06222851265088478, 0.3007046293583137]\n)\n])\ncomponents[2] (prior = 0.8532): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(4), p=[0.2690392997421659, 0.2787315703356248, 0.3487169428115867, 0.10351218711062272]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.3946958795419896, 0.6053041204580105]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.037114970670514356, 0.685642120461795, 0.27724290886769054]), Distributions.Categorical{Float64, Vector{Float64}}(\nsupport: Base.OneTo(5)\np: [0.13972452236299424, 0.09991697556277244, 0.07852727810887644, 0.24002277289180454, 0.4418084510735524]\n)\n])\ncomponents[3] (prior = 0.0496): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(4), p=[0.3698227487483096, 1.532751121763546e-5, 0.04816642960243212, 0.5819954941380405]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.2621341506389576, 0.7378658493610424]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.39788350529281125, 0.01857205016963969, 0.5835444445375491]), Distributions.Categorical{Float64, Vector{Float64}}(\nsupport: Base.OneTo(5)\np: [0.3053588789604636, 0.22073316378657493, 0.15584416763195688, 0.021340790777373764, 0.29672299884363085]\n)\n])\n"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "cell_type": "code",
   "source": [
    "@btime fit!(model_, $data_with_mix, tol=1e-3, max_iter=1000) setup = (model_ = deepcopy(model_0))\n",
    "@btime ExpectationMaximization.fit_mle(dist_ini, $(permutedims(data_with_mix)), atol=1e-3, maxiter=1000)"
   ],
   "metadata": {},
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10000-element Vector{Int64}:\n 2\n 2\n 2\n 2\n 2\n 2\n 2\n 2\n 2\n 2\n ⋮\n 2\n 2\n 2\n 2\n 2\n 2\n 2\n 2\n 2"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "cell_type": "code",
   "source": [
    "LCA_p_class, LCA_p_proba = LatentClassAnalysis.predict(model, data_with_mix)\n",
    "EM_p_proba = ExpectationMaximization.predict_proba(dist_fit, permutedims(data_with_mix))\n",
    "EM_p_class = ExpectationMaximization.predict(dist_fit, permutedims(data_with_mix))"
   ],
   "metadata": {},
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test results are the same"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "cell_type": "code",
   "source": [
    "@test EM_p_proba ≈ LCA_p_proba"
   ],
   "metadata": {},
   "execution_count": 28
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "cell_type": "code",
   "source": [
    "@test EM_p_class == LCA_p_class"
   ],
   "metadata": {},
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Other EM algo"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MixtureModel{Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}}(K = 3)\ncomponents[1] (prior = 0.0304): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(4), p=[0.0, 0.39473684210526316, 0.2006578947368421, 0.4046052631578947]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.6809210526315789, 0.319078947368421]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.0, 0.3125, 0.6875]), Distributions.Categorical{Float64, Vector{Float64}}(\nsupport: Base.OneTo(5)\np: [0.3026315789473684, 0.08881578947368421, 0.0, 0.18421052631578946, 0.42434210526315785]\n)\n])\ncomponents[2] (prior = 0.8288): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(4), p=[0.27002895752895756, 0.27871621621621623, 0.3556949806949807, 0.09555984555984556]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.388996138996139, 0.6110038610038611]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.040781853281853284, 0.6922055984555985, 0.2670125482625483]), Distributions.Categorical{Float64, Vector{Float64}}(\nsupport: Base.OneTo(5)\np: [0.1369449806949807, 0.09905888030888031, 0.07806467181467182, 0.2422779922779923, 0.4436534749034749]\n)\n])\ncomponents[3] (prior = 0.1408): Distributions.Product{Distributions.Discrete, Distributions.Categorical{Float64, Vector{Float64}}, Vector{Distributions.Categorical{Float64, Vector{Float64}}}}(v=Distributions.Categorical{Float64, Vector{Float64}}[Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(4), p=[0.23082386363636365, 0.04332386363636364, 0.021306818181818184, 0.7045454545454546]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(2), p=[0.46590909090909094, 0.5340909090909091]), Distributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.25497159090909094, 0.12713068181818182, 0.6178977272727273]), Distributions.Categorical{Float64, Vector{Float64}}(\nsupport: Base.OneTo(5)\np: [0.3700284090909091, 0.16548295454545456, 0.13920454545454547, 0.0390625, 0.28622159090909094]\n)\n])\n"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "cell_type": "code",
   "source": [
    "dist_fit_EM_stochastic = fit_mle(dist_ini, permutedims(data_with_mix), atol=1e-3, maxiter=1000, method = StochasticEM()) # from ExpectationMaximization.jl"
   ],
   "metadata": {},
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
